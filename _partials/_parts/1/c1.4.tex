

\chapter{Trainning Algorithms}

\section{Taxonomy of Training Algorithms}
From the form of data utilized in the training, we could categories training algorithms of spike neural network
into largely two categories: unsupervior learning and supervise learning.
While unsupervior learning not explictly specify the expect outcomes in the dataset and align the model to these
explicit-specified outcomes , supervior learning explictly specify the expect outcomes in the dataset.

From the theory basis, in this book, we categories the training algorithms into $4$ categories:
\begin{itemize}
\item \textbf{surrogate gradient descending methods}: The basic idea of surrogate gradient descending methods
are utilize surrogate methods to solve the undifferntial term $\frac{\partial S(t)}{\partial w_{ij}}$
appear in the gradient descending-based loss optimizations. $S(t)$ is a spike train of a neuron, and $w_{ij}$
is the synapse weight from neuron $j$ to neuron $i$.

\item \textbf{bio-phenomena-based methods}: The bio-phenomena-based inspired by bio-phenomena to adjust the 
weights dynamically. One kind of these methods is the spike-timing-dependent plasticity (STDP)-based methods,
 which inspired by the \textit{long-term potentiation (LTP)} and the \textit{long-term depression (LTD)} in
 the bioneural networks. Base on the difference in time of the the spike emit from pre-post neurons, STDP-based
 methods adjust the synapse weights. 

\item \textbf{statistical mechanism-based methods}:
Statistical mechanism-based methods tackle the whole networks as a statistical mechanism system.
Statistical mechanism methods are used to model the property (e.g., system energy), and the interaction 
between neurons. With optimize on the system energy, we adjust the weights of synapses.

\item \textbf{observation methods}:
rather than well-train the neural network, observation methods focus on design and training 
observation models on the neural network. As the system property of neural network at a certain time $t$,
contains rich information about the dynamics of input data, by well-design an observation method, 
we has the potential to obtain the outcomes we expect.

\end{itemize}



\section{Unsupervior Learning}
\subsection{Spike-timing-dependent plasticity (STDP)}
% STDP can be devised from information maximizing principles (Bohte and Mozer, 2007; Toyoizumi et al., 2005).
\subsection{Growing Spiking Neural Networks}
\subsection{Artola, Bröcher, Singer (ABS) rule}
\subsection{Bienenstock, Cooper, Munro (BCM) rule}
\subsection{Relationship between BCM and STDP rules}

\section{Supervised Learning}

\subsection{STDP-based Methods}
\subsubsection{Supervised STDP (SSTDP)}
\subsubsection{Spike-Timing-Dependent Plasticity (STDP) with Supervision}

\subsection{Spike-Timing Dependent Backpropagation (STDBP)}

\subsection{Liquid State Machine (LSM) and Readout Training}

\subsection{SpikeProp}



\textbf{Extension}
(McKennoch et al., 2006; Booij and tat Nguyen, 2005; Shrestha and Song, 2015; de Montigny and Mâsse, 2016; Banerjee, 2016; Shrestha and Song, 2017).

spike timing based methods is that they cannot learn starting from a quiescent state of no spiking.
Bohte (2011)

Huh and Sejnowski (2017)

\subsection{ReSuMe}
\textbf{Related Work}
(Sporea and Grüning, 2013)
Pfister et al. (2006)
Gardner et al. (2015)
Fremaux et al. (2010)


\subsection{SuperSpike}
SuperSpike~\cite{super-spike} is a supervised learning algorithm dedicated to deterministic
 Leaky Intergrate-and-Fire neuron model. While the backpropagation algorithm used in 
 traditional neural network cannot directly be used in the training of spiking neural network,
 the author provide a surrogate gradient-based method to tackling with the problems facing
 in solving the $S_i/\partial w_{ij}$, where $S_i$ is the $i$-th neuron's spike train, and 
 $w_{ij}$ is the connection weight from neuron $j$ to neuron $i$.

 Specifically, $S_i(t) = \sum_{k} \delta(t - t_k)$, where $t_k$ is the $k$-th spike emission time,
 and $\delta(\cdot)$ is the dirac delta function.


\textbf{Approaches}
approximate the partial derivative of the hidden unit output by $f(S_{pre},  g(V_{post}))$.

Let $\hat S_i$ be the target spike train of neuron $i$.
The cost model for optimization that make $\hat S_i$ approach the real $S_i$ hold the form:
$L=\frac12 \int_{-\infty}^t ds[(\alpha * \hat S_i - \alpha * S_i)(s)]^2$.

$\alpha$ is a normalized smooth temporal convolution kernel. The original SuperSPike use 
\textit{double exponential causal kernel}.

$$\partial L/\partial w_{ij}=-\int_{-\infty}^t ds[(\alpha * \hat S_i - \alpha * S_i)(s)](\alpha * \frac{\partial S_i}{\partial w_{ij}})(s)$$.

Some existing methods for tackling the term $\frac{\partial S_i}{\partial w_{ij}}$:
(1) making derivation directly to the membrance voltage, 
(2) introducing noisy which render the likelihood of $\langle S_i \rangle$ a smooth function of the membrance potential.

The superspike convert calculation of $\frac{\partial S_i}{\partial w_{ij}}\rightarrow \sigma'(U_i)\frac{\partial U_i}{\partial w_{ij}}$.
In which $U_i$ is the membrance voltage.
Original superspike choose $\sigma(U)$ be the negative side of a fast sigmoid.
This function is objective to increase steeply and peak at the spiking threshold.
Other monotonic functions may also work.

For current-based LIF models the membrane potential $U_i(t)$ can be written in integral form as 
a spike response model (SRM0 (Gerstner et al., 2014)):
$U_i(t) = \sum_j w_{ij} (\epsilon * S_j(t)) + (\eta * S_i(t))$ 



In which, $\epsilon$ corresponds to the postsynaptic potential (PSP) shape, $\eta$ captures 
spike dynamics and reset.

The existence of term $(\eta * S_i(t))$ make us difficult to perform derivation. Now, 
$U_i(t)\approx (\epsilon * S_j(t))$.

The gradient calculation for a weight become:
$$\frac{\partial w_{ij}}{\partial t}=r\int_{-\infty}^t ds e_i(s) \alpha * (\sigma'(U_i(s))(\epsilon * S_j)(s))$$.

$r$ is the learning rate, $e_i(s)\equiv \alpha * (\hat S_i - S_i)$, $\lambda_{ij} = \alpha * (\sigma'(U_i(s))(\epsilon * S_j)(s))$
 is the eligibility trace. The form above is also known as \textit{non-vanishing surrogate gradient}.

The neuron model utilized by the SuperSpike is $$\tau^{mem}\frac{dU_i}{dt} = (U^{rest} -U_i) +I_i^{syn}(t)$$.
And synapse evolution model is $$\frac{d}{dt} I_i^{syn}(t) =-\frac{I_i^{syn}(t)}{\tau^{syn}} + \sum_{j\in pre}w_{ij}S_j(t)$$.

% \textbf{Distal Reward Problem}
% \textbf{Eligibility trace}

% \textbf{Causal Convolution}


% Nonlinear Hebbian term detects coincidences between presynaptic activity and postsynaptic depolarization.
% Hebbian three factor rule
% These spatiotemporal coincidences at the single synapse wij are then stored transiently by the temporal 
% convolution with the causal kernel $\alpha$.
% This step can be interpreted as a synaptic eligibility trace, which in neurobiology could for instance be
%  implemented as a calcium transient or a related signaling cascade.

%  $$\frac{\partial w_{ij}}{\partial t}=r_{ij}\int_{t_k}^{t_{k+1}} e_i(s) \alpha * (\sigma'(U_i(s))(\epsilon * S_j)(s))ds$$.

%  $\epsilon$ is a double exponential filter.
%  The original SuperSpike use two single exponential filter to realize it.
%  In each time step, it firstly integrate the single exponential trace by
%   $\frac{dz_j}{dt}=-\frac{z_j}{\tau_{rise}} + S_j(t)$.
%   It then fed into a second exponential filter array $\tau_{decay} \frac{\tilde z_j}{dt}=-\tilde z_j + z_j$.

%   $\tilde z_j(t) \equiv (\epsilon * S_j)(t)$.

%   $\sigma'(U_i) =(1+|h_i|^2)$ with $h_i \equiv \beta(U_i-\ell)$, where $\ell$ is the neuronal firing threshold.

%   Error signals include output error signal and feedback error signal. The formmer is the error between output
%    spike train and predicted spike train. Feedback signals are signals that derived from the output error signal.

%   $\alpha \propto \epsilon$.
%   For output signal $e_i = -\alpha * (\tilde S_i - S_i)$.
%   For feedback signals
%   (1) Symmetric Feedback: $e_i = \sum_k w_{ki}e_k$,
%   (2) Random Feedbck: $e_i = \sum_k b_{ki}e_i$, where $b_{ki}\sim N(0,1)$,
%   (3) Uniform Feedback: $e_i = \sum_k e_k$.

%   For weight update it use a separate variable $m_{ij}$ in a specific chunk size $t_b$.
%   $m_{ij} \leftarrow m_{ij} + g_{ij}$, $g_{ij}(t) = e(t)\lambda_{ij}(t)$.
%     At the end of each $t_b$, $w_{ij} \leftarrow w_{ij} + r_{ij}m_{ij}$, where $r_{ij}$ it
%     the learning rates.
%     They ensure $-0.1 < w_{ij} < 0.1$.

%     In some experiment, regularity term may be added in the the weight learning rule.
%     $$\frac{\partial w_{ij}^{hid}}{\partial t} = r_{ij}\int_{t_k}^{t_{k + 1}}e_i(s)(\alpha * (\sigma'(U_i(s))(\epsilon * S_j)(s))-\rho w_{ij}e_i(s)z_i^4) ds$$.

%     Regularization strength $\rho$ was chosen to be the square of error.

%     $\frac{z_i}{dt} = -\frac{z_i}{\tau_{het}}+S_i(t)$.

% \textbf{Pprobabilistic escape rate model (Pfister et al. (2006))}

% \textbf{Victor-Pupura distance-based learning (Victor and Purpura, 1997)}

% \textbf{Convergence properties of rules that reduce the van Rossum distance 
% by gradient descent. (Gardner and Grüning (2016) and Albers et al. (2016))}

% \textbf{Learning algorithm Proposed by Memmesheimer et al. (2014)}

% \textbf{Sequence Learning Problem as a Variational Learning Problem}

% \textbf{Combining adaptive control theory with heterogeneous neurons. (Gilra and Gerstner, 2017)}

% \textbf{Tempotron (Gütig and Sompolinsky, 2006; Gütig, 2016)}
% can be derived as a gradient-based approach (Urbanczik and Senn, 2009).


% It is chanllenging in calcultion of $\frac{\partial S_i(t)}{\partial w_{ij}}$, where $S_i(t) = \sum_k \delta(t-t_i^k)$.
% $S_i(t)$ is the spike train of neuron $i$.



\subsection{SPAN (Mohemmed et al., 2012)}

\subsection{Remote Supervised Method (ReSuMe)}
\subsection{FreqProp}
\subsection{Local error-driven associative biologically realistic algorithm (LEABRA)}
\subsection{Supervised Hebbian Learning}

\section{Reinforcement Learning}
\subsection{Spiking Actor-Critic method}
\subsection{STDP-based Methods}

\section{Convert Trandictional ANN to SNN}